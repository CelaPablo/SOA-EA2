{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prueba 1 - Vectores - GPU.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw-Vno_15t-E"
      },
      "source": [
        "# 1 Introducción\n",
        "El siguiente cuaderno realiza la suma de dos vectores, utilizando GPGPU. El algoritmo está basado en la función axpy nivel 1[3], de la biblioteca BLAS[4] que resuelve la ecuación:\n",
        "<center>$Y=\\alpha X + Y$</center>\n",
        "\n",
        "Su objetivo es enseñar a los alumnos como se utiliza Python [2] la plataforma Colab[1] y CUDA[5,6]. Mostrando el funcionamiento y granularidad (grilla, bloque, warps) de sobre una dimensión (x)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cRnhv_7N4Pa"
      },
      "source": [
        "---\n",
        "# 2 Armado del ambiente\n",
        "Instala en el cuaderno el módulo CUDA de Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z74FNbCszDmw"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzQaWRTtc1Zj"
      },
      "source": [
        "---\n",
        "# 3 Desarrollo\n",
        "Ejecuta el Código CPU - GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c7mZSnu0M3m"
      },
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "#@title 3.1 Parámetros de ejecución { vertical-output: true }\n",
        "cantObjetos = 10000 #@param {type:\"slider\", min:1000, max:10000, step:1}\n",
        "velocidadMaxima =   200#@param {type: \"integer\", min:0}\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "from datetime import datetime\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy\n",
        "\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Definición de función que transforma el tiempo en  milisegundos --------------\n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Cota para la masa ------------------------------------------------------------\n",
        "masaMax = 100\n",
        "\n",
        "try: \n",
        "  if velocidadMaxima <= 0:\n",
        "    raise ValueError(\"La velocidad maxima debe ser mayor a 0.\");\n",
        "\n",
        "  masa_cpu = numpy.random.randint(1, masaMax, size=cantObjetos)\n",
        "  masa_cpu = masa_cpu.astype(numpy.int32())\n",
        "\n",
        "  velocidad_cpu = numpy.random.uniform(1, velocidadMaxima, size=cantObjetos)\n",
        "  velocidad_gpu = velocidad_cpu.astype(numpy.float32())\n",
        "\n",
        "  energia_cpu = numpy.empty_like(velocidad_cpu)\n",
        "\n",
        "  # CPU - reservo la memoria GPU -----------------------------------------------\n",
        "  masa_gpu = cuda.mem_alloc(masa_cpu.nbytes)\n",
        "  velocidad_gpu = cuda.mem_alloc(velocidad_cpu.nbytes)\n",
        "  energia_gpu = cuda.mem_alloc(energia_cpu.nbytes)\n",
        "\n",
        "  # GPU - Copio la memoria al GPU ----------------------------------------------\n",
        "  cuda.memcpy_htod(masa_gpu, masa_cpu)\n",
        "  cuda.memcpy_htod(velocidad_gpu, velocidad_cpu)\n",
        "  cuda.memcpy_htod(energia_gpu, energia_cpu)\n",
        "\n",
        "  # CPU - Defino la función kernel que ejecutará en GPU ------------------------\n",
        "  module = SourceModule(\"\"\"\n",
        "  __global__ void kernel_cinetica(int n, int *mgpu, float *vgpu, float * egpu)\n",
        "  {\n",
        "    int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "    if( idx < n )\n",
        "    {\n",
        "      egpu[idx] = 0.5 * (mgpu[idx] * pow(vgpu[idx], 2));\n",
        "    }\n",
        "  }\n",
        "  \"\"\") \n",
        "\n",
        "  kernel = module.get_function(\"kernel_cinetica\")\n",
        "\n",
        "  tiempo_gpu = datetime.now()\n",
        "\n",
        "  # GPU ------------------------------------------------------------------------\n",
        "  dim_hilo = 256\n",
        "  dim_bloque = numpy.int( (cantObjetos + dim_hilo-1) / dim_hilo )\n",
        "\n",
        "  kernel(numpy.int32(cantObjetos), masa_gpu, velocidad_gpu, energia_gpu, block=( dim_hilo, 1, 1 ),grid=(dim_bloque, 1,1) )\n",
        "  tiempo_gpu = datetime.now() - tiempo_gpu\n",
        "\n",
        "  # Copio el resultado desde la memoria GPU ------------------------------------\n",
        "  cuda.memcpy_dtoh(energia_cpu, energia_gpu)\n",
        "\n",
        "  tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "  print( \"Cantidad de elementos: \", cantObjetos )\n",
        "  print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "  print(\"Tiempo GPU: \", tiempo_en_ms( tiempo_gpu   ), \"[ms]\" )\n",
        "  print(\"Tiempo Total: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "  \n",
        "\n",
        "except ValueError as valerr:\n",
        "  print (valerr)\n",
        "# except: \n",
        "#   print(\"Houston we have a problem!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EALIlyyG6iqP"
      },
      "source": [
        "---\n",
        "# 4 Tabla de pasos de ejecución del programa\n",
        "\n",
        "\n",
        " Procesador | Funciòn | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  @param                | Lectura del tamaño de vectores desde Colab.\n",
        "CPU      |  import                | Importa los módulos para funcionar.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  numpy.random.randn( Cantidad_N ) | Inicializa los vectoes A, B y R.\n",
        "**GPU**  |  cuda.mem_alloc()      | Reserva la memoria en GPU.\n",
        "**GPU**  |  cuda.memcpy_htod()    | Copia las memorias desde el CPU al GPU.\n",
        "CPU      |  SourceModule()        | Define el código del kernel \n",
        "CPU      |  module.get_function() | Genera la función del kernel GPU\n",
        "CPU      |  dim_tx/dim_bx         | Calcula las dimensiones.\n",
        "**GPU**  |  kernel()              | Ejecuta el kernel en GPU\n",
        "CPU      |  cuda.memcpy_dtoh( )   | Copia el resultado desde GPU memoria A a CPU memoria R.\n",
        "CPU      |  print()               | Informo los resultados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzgZkrQD-UTy"
      },
      "source": [
        "---\n",
        "# 5 Conclusiones\n",
        "\n",
        "Las conclusiones son explicadas en clase....\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hn6HOCYEjyY"
      },
      "source": [
        "---\n",
        "# 6 Bibliografia\n",
        "\n",
        "[1] MARKDOWN SYNTAX Colab: [PDF](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/markdown-cheatsheet-online.pdf)\n",
        "\n",
        "[2] Introducción a Python: [Página Colab](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/Python_Basico.ipynb) \n",
        "\n",
        "[3] Función Axpy de biblioteca BLAS: [Referencia](https://software.intel.com/content/www/us/en/develop/documentation/mkl-developer-reference-c/top/blas-and-sparse-blas-routines/blas-routines/blas-level-1-routines-and-functions/cblas-axpy.html)\n",
        "\n",
        "[4] Biblioteca BLAS: [Referencia](http://www.netlib.org/blas/)\n",
        "\n",
        "[5] Documentación PyCUDA: [WEB](https://documen.tician.de/pycuda/index.html)\n",
        "\n",
        "[6] Repositorio de PyCUDA: [WEB](https://pypi.python.org/pypi/pycuda)\n",
        "\n",
        "\n"
      ]
    }
  ]
}