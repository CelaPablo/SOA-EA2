{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cela_Pablo_ejercicio_2_reentrega_extra.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPm0fx2HfKbOiMWwyn1U3zh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CelaPablo/SOA-EA2/blob/master/HPC/Cela_Pablo_ejercicio_2_reentrega_extra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbY9yhjAmiE3"
      },
      "source": [
        "# Introducción\n",
        "\n",
        "En el siguiente ejercicio, se realiza la suma de 3 matrices[1] cuadradas de N cantidad de elementos ingresado por parametro.\n",
        "\n",
        "Para realizar dicha operación, se suma cada elemento de cada matriz y se lo guarda en una nueva matriz. \n",
        "\n",
        "<center>R[Xi][Yi] = A[Xi][Yi] + B[Xi][Yi] + C[Xi][Yi]</center>\n",
        "\n",
        "Con este ejercicio, se pretende entender el funcionamiento basico del Lenguaje Python [2], Google Colab [3,4] y tratamiento de imagenes a bajo nivel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1QT13dNnGLX"
      },
      "source": [
        "---\n",
        "# Armado del ambiente\n",
        "\n",
        "Instala en el cuaderno el módulo CUDA de Python.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsNGAlTpmAPk"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn6HTAPBnqjN"
      },
      "source": [
        "#@title ## Parámetros de ejecución\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Especifique la cantidad de elementos que conforman la fila / columna:\n",
        "cantidad = 10000 #@param {type:\"slider\", min:1000, max:10000, step:1}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6F3dpTGoVFt"
      },
      "source": [
        "# Desarrollo - Ejecución CPU - CPUGPU.\n",
        "\n",
        "Suma de matrices cuadradas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_UcJ5iGoekE",
        "outputId": "cd304f78-06de-4d24-d471-70834d3a434b"
      },
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Definición de función que transforma el tiempo en  milisegundos --------------\n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "try:\n",
        "  %matplotlib inline\n",
        "  from datetime import datetime\n",
        "  import numpy\n",
        "  import pycuda.driver as cuda\n",
        "  import pycuda.autoinit\n",
        "  from pycuda.compiler import SourceModule\n",
        "\n",
        "  tiempo_total = datetime.now()\n",
        "\n",
        "  matrizA = numpy.random.randint(low=0,high=50,size=(cantidad, cantidad))\n",
        "  matrizB = numpy.random.randint(low=0,high=50,size=(cantidad, cantidad))\n",
        "  matrizC = numpy.random.randint(low=0,high=50,size=(cantidad, cantidad))\n",
        "\n",
        "  matrizCPU = numpy.zeros_like(matrizA)\n",
        "  matrizGPU = numpy.zeros_like(matrizA)\n",
        "\n",
        "  # Desarrollo secuencial. -----------------------------------------------------\n",
        "  tiempo_secuencial = datetime.now()\n",
        "\n",
        "  for x in range(0, cantidad):\n",
        "    for y in range(0, cantidad):\n",
        "      matrizCPU[x][y] = matrizA[x][y] + matrizB[x][y] + matrizC[x][y]\n",
        "\n",
        "  tiempo_secuencial = datetime.now() - tiempo_secuencial\n",
        "\n",
        "  # Cargo las matrices en GPU. -------------------------------------------------\n",
        "  matrizAGPU = cuda.mem_alloc(matrizA.nbytes)\n",
        "  matrizBGPU = cuda.mem_alloc(matrizB.nbytes)\n",
        "  matrizCGPU = cuda.mem_alloc(matrizC.nbytes)\n",
        "  matrizRGPU = cuda.mem_alloc(matrizGPU.nbytes)\n",
        "\n",
        "  cuda.memcpy_htod(matrizAGPU, matrizA)\n",
        "  cuda.memcpy_htod(matrizBGPU, matrizB)\n",
        "  cuda.memcpy_htod(matrizCGPU, matrizC)\n",
        "  cuda.memcpy_htod(matrizRGPU, matrizGPU)\n",
        "\n",
        "  # CPU - Defino la función kernel que ejecutará en GPU ------------------------\n",
        "  module = SourceModule(\"\"\"\n",
        "  __global__ void kernel_suma(int cant, int *Agpu, int *Bgpu, int *Cgpu, int *Rgpu)\n",
        "  {\n",
        "    int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "    int idy = threadIdx.y + blockIdx.y*blockDim.y;\n",
        "    int cantidad = cant * cant;\n",
        "    \n",
        "    if(idx < cantidad && idy < cantidad)\n",
        "    {\n",
        "      int index = idx * cant + idy;\n",
        "      Rgpu[index] = Agpu[index] + Bgpu[index] + Cgpu[index];\n",
        "    }\n",
        "  }\n",
        "  \"\"\") \n",
        "\n",
        " # CPU - Genero la función kernel. --------------------------------------------\n",
        "  kernel = module.get_function(\"kernel_suma\")\n",
        "\n",
        "  tiempo_paralelo = datetime.now()\n",
        "\n",
        "  # Se calculan las dimensiones de trabajo. ------------------------------------\n",
        "  dim_hilo_x = 16\n",
        "  dim_bloque_x = numpy.int((cantidad+dim_hilo_x-1) / dim_hilo_x)\n",
        "\n",
        "  dim_hilo_y = 16\n",
        "  dim_bloque_y = numpy.int((cantidad+dim_hilo_y-1) / dim_hilo_y)\n",
        "\n",
        "  kernel(numpy.int32(cantidad), matrizAGPU, matrizBGPU, matrizCGPU, matrizRGPU, block=(dim_hilo_x, dim_hilo_y, 1), grid=(dim_bloque_x, dim_bloque_y,1))\n",
        "\n",
        "  # GPU - Copio el resultado desde la memoria GPU. -----------------------------\n",
        "  cuda.memcpy_dtoh(matrizGPU, matrizRGPU)\n",
        "\n",
        "  tiempo_paralelo = datetime.now() - tiempo_paralelo\n",
        "  tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "  print( \"Tiempo en ejecucion secuencial:\", tiempo_en_ms(tiempo_secuencial), \"[ms]\")\n",
        "  print( \"Tiempo en ejecucion paralela:\", tiempo_en_ms(tiempo_paralelo), \"[ms]\")\n",
        "  print( \"Tiempo Total:\", tiempo_en_ms(tiempo_total), \"[ms]\")\n",
        "\n",
        "except ValueError as valerr:\n",
        "  print(valerr)\n",
        "except FileNotFoundError:\n",
        "  print(\"No se pudo abrir la imagen: \", imagepath)\n",
        "except ModuleNotFoundError:\n",
        "  print(\"Primero deben instalarse las dependencias - Armado del ambiente e instalaciónn de CUDA.\")\n",
        "except: \n",
        "  print(\"Houston we have a problem!\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tiempo en ejecucion secuencial: 143829.274 [ms]\n",
            "Tiempo en ejecucion paralela: 195.0 [ms]\n",
            "Tiempo Total: 147738.312 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQPfKzH191WB"
      },
      "source": [
        "---\n",
        "# Tabla de pasos de ejecución del programa\n",
        "\n",
        "\n",
        " Procesador | Función | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  @param                | Lectura de la cantidad de valores de las filas y columnas de las matrices (N).\n",
        "CPU      |  import                | Importa los módulos para funcionar.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  numpy.random          | Crea las tres matrices de enteros con numeros aletorios - Matrices de NxN.\n",
        "CPU      |  numpy.zeros_like      | Crea las matrices resultantes inicializados en 0.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  for...for...          | Se realiza la suma de las matrices en forma secuencial.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "**GPU**  |  cuda.mem_alloc        | Reservo memoria enn GPU.\n",
        "**GPU**  |  cuda.memcpy_htod      | Se copia la memoria CPU en GPU.\n",
        "CPU      |  SourceModule          | Defino el codigo que va a ejecutar el kernel.\n",
        "CPU      |  module.get_function() | Genera la función del kernel GPU.\n",
        "CPU      |  dim_tx/dim_bx         | Calcula las dimensiones.\n",
        "**GPU**  |  kernel()              | Ejecuta el kernel en GPU.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  cuda.memcpy_dtoh( )   | Copia el resultado desde GPU a CPU.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  print()               | Informe de los resultados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvCdj9kdAAfa"
      },
      "source": [
        "---\n",
        "# Conclusión\n",
        "\n",
        "Si bien el ejercicio realizado no presenta una gran complejidad, me sirvio para aprender a manipular matrices de una manera distinta a la que estoy acostumbrado (tratandolo como si fuese un array). Tambien me sirvio para entender un poco mas las funciones que ofrece Numpy y lo facil que se pueden crear y manipular arrays/matrices.\n",
        "\n",
        "En cuanto a los resultados, la resolución en paralelo es despreciable con respecto a la ejecución secuencial. Solo se ve afectada cuando el N ingresado es demasiado chico (menor a 10). A medida que se incrementa el N ingresado, la ejecución paralela se mantiene lineal mientras que la ejecución secuencial se comporta de forma exponencial (respecto al tiempo). \n",
        "\n",
        "Cabe mencionar, que si el N es demasiado grande ( mayor al millon), la RAM que ofrece Colab, no nos es suficiente para realizar el calculo de la suma.\n",
        "\n",
        "## Pasos mas relevantes\n",
        "1- Generar matrices aleatorias.\n",
        "\n",
        "2- Reservar memoria en GPU (cuda.mem_alloc).\n",
        "\n",
        "3- Copiar datos en memoria GPU (cuda.memcpy_htod).\n",
        "\n",
        "4- Definir la función que va a ejecutar el Kernel.\n",
        "\n",
        "5- Calcular las dimensiones.\n",
        "\n",
        "6- Ejecucion Paralela.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytwm04n0mvy8"
      },
      "source": [
        "---\n",
        "# Bibliografía\n",
        "\n",
        "[1] Suma de Matrices: [WEB](https://economipedia.com/definiciones/suma-de-matrices.html)\n",
        "\n",
        "[2] MARKDOWN SYNTAX Colab: [PDF](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/markdown-cheatsheet-online.pdf)\n",
        "\n",
        "[3] Introducción a Python: [Página Colab](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/Python_Basico.ipynb) \n",
        "\n",
        "[4] Tutorial Point Colab: [PDF](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/markdown-cheatsheet-online.pdf)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}